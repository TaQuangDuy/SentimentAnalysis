{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8442949,"sourceType":"datasetVersion","datasetId":5030235}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-19T06:55:12.067595Z","iopub.execute_input":"2024-05-19T06:55:12.068333Z","iopub.status.idle":"2024-05-19T06:55:24.849146Z","shell.execute_reply.started":"2024-05-19T06:55:12.068291Z","shell.execute_reply":"2024-05-19T06:55:24.847919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc \ndef report_gpu(): \n    print(torch.cuda.list_gpu_processes()) \n    gc.collect() \n    torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T06:55:24.851564Z","iopub.execute_input":"2024-05-19T06:55:24.851945Z","iopub.status.idle":"2024-05-19T06:55:24.857687Z","shell.execute_reply.started":"2024-05-19T06:55:24.851907Z","shell.execute_reply":"2024-05-19T06:55:24.856688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\nimport torch.nn as nn\nfrom transformers import AdamW, get_linear_schedule_with_warmup","metadata":{"execution":{"iopub.status.busy":"2024-05-19T06:56:19.481254Z","iopub.execute_input":"2024-05-19T06:56:19.481990Z","iopub.status.idle":"2024-05-19T06:56:19.487412Z","shell.execute_reply.started":"2024-05-19T06:56:19.481953Z","shell.execute_reply":"2024-05-19T06:56:19.486526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_file_path = \"/kaggle/input/review/preprocessed_train_data.csv\"\ntest_file_path = \"/kaggle/input/review/preprocessed_test_data.csv\"","metadata":{"execution":{"iopub.status.busy":"2024-05-19T06:55:42.824292Z","iopub.execute_input":"2024-05-19T06:55:42.825043Z","iopub.status.idle":"2024-05-19T06:55:42.829281Z","shell.execute_reply.started":"2024-05-19T06:55:42.825013Z","shell.execute_reply":"2024-05-19T06:55:42.828220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(train_file_path)\ntest_data = pd.read_csv(test_file_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T06:56:24.324389Z","iopub.execute_input":"2024-05-19T06:56:24.324732Z","iopub.status.idle":"2024-05-19T06:56:29.245092Z","shell.execute_reply.started":"2024-05-19T06:56:24.324706Z","shell.execute_reply":"2024-05-19T06:56:29.244164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_texts, val_texts, train_labels, val_labels = train_test_split(train_data['text'], train_data['label'], test_size=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T06:56:30.648463Z","iopub.execute_input":"2024-05-19T06:56:30.649296Z","iopub.status.idle":"2024-05-19T06:56:30.818304Z","shell.execute_reply.started":"2024-05-19T06:56:30.649264Z","shell.execute_reply":"2024-05-19T06:56:30.817533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', download=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T06:56:34.038897Z","iopub.execute_input":"2024-05-19T06:56:34.039745Z","iopub.status.idle":"2024-05-19T06:56:35.352178Z","shell.execute_reply.started":"2024-05-19T06:56:34.039713Z","shell.execute_reply":"2024-05-19T06:56:35.351418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SentimentDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len=512):\n        self.texts = texts.dropna()\n        self.labels = labels.dropna()\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts.iloc[idx] if idx < len(self.texts) else \"\"\n        label = self.labels.iloc[idx] if idx < len(self.labels) else 0\n\n        # Tokenize the text\n        tokens = self.tokenizer(\n            text,\n            padding='max_length',\n            truncation=True,\n            max_length=self.max_len,\n            return_tensors='pt'\n        )\n\n        input_ids = tokens.input_ids.squeeze()\n        attention_mask = tokens.attention_mask.squeeze()\n\n        # Adjust for texts longer than max_len\n        if input_ids.size(0) > self.max_len - 2:  # accounting for [CLS] and [SEP] tokens\n            first_part = input_ids[:201]  # 201 tokens for the first part\n            last_part = input_ids[-311:]  # 311 tokens for the last part\n            input_ids = torch.cat([first_part, last_part])\n\n            first_mask = attention_mask[:201]  # Mask for the first part\n            last_mask = attention_mask[-311:]  # Mask for the last part\n            attention_mask = torch.cat([first_mask, last_mask])\n\n        # Ensure uniform length by padding if necessary\n        if input_ids.size(0) < self.max_len:\n            padding_length = self.max_len - input_ids.size(0)\n            input_ids = F.pad(input_ids, (1, padding_length + 1), value=self.tokenizer.pad_token_id)\n            attention_mask = F.pad(attention_mask, (1, padding_length + 1), value=0)\n\n        return {\n            'input_ids': input_ids,\n            'attention_mask': attention_mask,\n            'labels': torch.tensor(label, dtype=torch.long)\n        }","metadata":{"execution":{"iopub.status.busy":"2024-05-19T06:56:37.565426Z","iopub.execute_input":"2024-05-19T06:56:37.566252Z","iopub.status.idle":"2024-05-19T06:56:37.576963Z","shell.execute_reply.started":"2024-05-19T06:56:37.566218Z","shell.execute_reply":"2024-05-19T06:56:37.576027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = SentimentDataset(train_texts, train_labels, tokenizer)\nval_dataset = SentimentDataset(val_texts, val_labels, tokenizer)\ntest_dataset = SentimentDataset(test_data['text'], test_data['label'], tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T06:56:40.344098Z","iopub.execute_input":"2024-05-19T06:56:40.345040Z","iopub.status.idle":"2024-05-19T06:56:40.491953Z","shell.execute_reply.started":"2024-05-19T06:56:40.344991Z","shell.execute_reply":"2024-05-19T06:56:40.490997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)\n#model.gradient_checkpointing_enable()\nmodel.classifier = nn.Linear(model.config.hidden_size, 5)\n# Freeze all layers except the last layer\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Enable gradient computation for the classifier layer\nfor param in model.classifier.parameters():\n    param.requires_grad = True","metadata":{"execution":{"iopub.status.busy":"2024-05-19T06:56:42.502922Z","iopub.execute_input":"2024-05-19T06:56:42.503611Z","iopub.status.idle":"2024-05-19T06:56:45.552378Z","shell.execute_reply.started":"2024-05-19T06:56:42.503577Z","shell.execute_reply":"2024-05-19T06:56:45.551460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T06:56:48.551863Z","iopub.execute_input":"2024-05-19T06:56:48.552681Z","iopub.status.idle":"2024-05-19T06:56:48.557541Z","shell.execute_reply.started":"2024-05-19T06:56:48.552651Z","shell.execute_reply":"2024-05-19T06:56:48.556514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW(model.classifier.parameters(), lr=2.5e-5)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T06:56:49.665114Z","iopub.execute_input":"2024-05-19T06:56:49.665741Z","iopub.status.idle":"2024-05-19T06:56:49.673328Z","shell.execute_reply.started":"2024-05-19T06:56:49.665707Z","shell.execute_reply":"2024-05-19T06:56:49.672242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\noutput_dir = \"/kaggle/working/results\"\nlogging_dir = \"/kaggle/working/logs\"\nos.makedirs(output_dir, exist_ok=True)\nos.makedirs(logging_dir, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T06:56:51.444103Z","iopub.execute_input":"2024-05-19T06:56:51.444467Z","iopub.status.idle":"2024-05-19T06:56:51.449726Z","shell.execute_reply.started":"2024-05-19T06:56:51.444437Z","shell.execute_reply":"2024-05-19T06:56:51.448654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n\nshutil.rmtree(output_dir, ignore_errors=True)\nshutil.rmtree(logging_dir, ignore_errors=True)\nos.makedirs(output_dir, exist_ok=True)\nos.makedirs(logging_dir, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T12:58:47.630399Z","iopub.execute_input":"2024-05-18T12:58:47.631288Z","iopub.status.idle":"2024-05-18T12:58:47.636876Z","shell.execute_reply.started":"2024-05-18T12:58:47.631253Z","shell.execute_reply":"2024-05-18T12:58:47.635816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=output_dir,\n    num_train_epochs=3,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir=logging_dir,\n    learning_rate=2.5e-5,\n    evaluation_strategy=\"epoch\",\n    save_total_limit=1,  # Keep only the last checkpoint\n    report_to=\"none\", \n)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T06:56:57.630573Z","iopub.execute_input":"2024-05-19T06:56:57.631276Z","iopub.status.idle":"2024-05-19T06:56:57.750493Z","shell.execute_reply.started":"2024-05-19T06:56:57.631244Z","shell.execute_reply":"2024-05-19T06:56:57.749615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T06:57:01.050161Z","iopub.execute_input":"2024-05-19T06:57:01.050936Z","iopub.status.idle":"2024-05-19T06:57:03.877354Z","shell.execute_reply.started":"2024-05-19T06:57:01.050900Z","shell.execute_reply":"2024-05-19T06:57:03.876220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_checkpoint(model, optimizer, epoch, filename='checkpoint.pth'):\n    state = {\n        'epoch': epoch,\n        'model_state': model.state_dict(),\n        'optimizer_state': optimizer.state_dict(),\n    }\n    torch.save(state, filename)\n    print(f\"Checkpoint saved to {filename}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-19T10:44:44.950733Z","iopub.execute_input":"2024-05-19T10:44:44.951091Z","iopub.status.idle":"2024-05-19T10:44:44.956314Z","shell.execute_reply.started":"2024-05-19T10:44:44.951061Z","shell.execute_reply":"2024-05-19T10:44:44.955400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_checkpoint(filename, model, optimizer):\n    if os.path.isfile(filename):\n        print(f\"Loading checkpoint {filename}\")\n        checkpoint = torch.load(filename)\n        model.load_state_dict(checkpoint['model_state'])\n        optimizer.load_state_dict(checkpoint['optimizer_state'])\n        epoch = checkpoint['epoch']\n        print(f\"Checkpoint loaded: start from epoch {epoch}\")\n        return epoch\n    else:\n        print(f\"No checkpoint found at {filename}\")\n        return 0","metadata":{"execution":{"iopub.status.busy":"2024-05-19T10:44:46.869628Z","iopub.execute_input":"2024-05-19T10:44:46.870456Z","iopub.status.idle":"2024-05-19T10:44:46.876090Z","shell.execute_reply.started":"2024-05-19T10:44:46.870420Z","shell.execute_reply":"2024-05-19T10:44:46.875088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_path = \"/kaggle/working/results/checkpoint-31000/\"\nstart_epoch = load_checkpoint(checkpoint_path, model, optimizer)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T10:57:18.195365Z","iopub.execute_input":"2024-05-19T10:57:18.196081Z","iopub.status.idle":"2024-05-19T10:57:18.200657Z","shell.execute_reply.started":"2024-05-19T10:57:18.196048Z","shell.execute_reply":"2024-05-19T10:57:18.199764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(start_epoch, training_args.num_train_epochs):\n    trainer.train()\n    save_checkpoint(model, optimizer, epoch, checkpoint_path)\n\n# Đánh giá mô hình\ntrainer.evaluate(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T10:42:47.167147Z","iopub.execute_input":"2024-05-19T10:42:47.167674Z","iopub.status.idle":"2024-05-19T10:42:52.542931Z","shell.execute_reply.started":"2024-05-19T10:42:47.167633Z","shell.execute_reply":"2024-05-19T10:42:52.541687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import BertForSequenceClassification, BertConfig, BertTokenizer\nfrom transformers import AdamW, get_linear_schedule_with_warmup\nfrom transformers.trainer_utils import get_last_checkpoint","metadata":{"execution":{"iopub.status.busy":"2024-05-19T10:53:45.629629Z","iopub.execute_input":"2024-05-19T10:53:45.630045Z","iopub.status.idle":"2024-05-19T10:53:45.635055Z","shell.execute_reply.started":"2024-05-19T10:53:45.630012Z","shell.execute_reply":"2024-05-19T10:53:45.634105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_path = \"/kaggle/working/results/checkpoint-31000/\"","metadata":{"execution":{"iopub.status.busy":"2024-05-19T10:54:44.156217Z","iopub.execute_input":"2024-05-19T10:54:44.156578Z","iopub.status.idle":"2024-05-19T10:54:44.160702Z","shell.execute_reply.started":"2024-05-19T10:54:44.156549Z","shell.execute_reply":"2024-05-19T10:54:44.159719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = BertConfig.from_pretrained(checkpoint_path + \"config.json\")\nmodel = BertForSequenceClassification(config)\nmodel.load_state_dict(torch.load(checkpoint_path + \"model.safetensors\"))\n\noptimizer = AdamW(model.parameters(), lr=5e-5)\noptimizer.load_state_dict(torch.load(checkpoint_path + \"optimizer.pt\"))\n\nscheduler = torch.load(checkpoint_path + \"scheduler.pt\")","metadata":{"execution":{"iopub.status.busy":"2024-05-19T10:55:54.520868Z","iopub.execute_input":"2024-05-19T10:55:54.521802Z","iopub.status.idle":"2024-05-19T10:55:54.691829Z","shell.execute_reply.started":"2024-05-19T10:55:54.521768Z","shell.execute_reply":"2024-05-19T10:55:54.690521Z"},"trusted":true},"execution_count":null,"outputs":[]}]}